---
title: "STA141A-ATW-Markdown"
author: "Andrew T. Weakley"
date: "12/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# --- Data processing and viz ---
library(latex2exp)
library(tidyverse)
library(broom)
library(gridExtra)
library(RColorBrewer)
# --- Stats---
library(corrplot)
library(boot)
library(mclust)
library(PCAtools)
library(MASS)
library(Hmisc)
# --- Spatial Analysis ---> Let's simplify our life haha
library(tmap)
library(leaflet)
#library(sp)
library(sf)
```

### --- Step 0: Packages to mess with --

```{r, eval=FALSE}
    if (!requireNamespace('BiocManager', quietly = TRUE))
        install.packages('BiocManager')

    BiocManager::install('PCAtools')
```


### --- Step 1: Data loading and procressing ---

```{r, "Part A-C: Load and process data I"}
## --- Part a: Upload Metadata for samples ---
path_data<-file.path(getwd(),"data")
META_DATA<-as_tibble(read.csv(file.path(path_data,"IMPROVE_metadata.csv")))
## --- Filter samples from Korea and Canada ---
US_META<-META_DATA %>% filter(Country %nin% c("KR","CA"))


## --- Filter stats not in continental US ---
US_META<-META_DATA %>% filter(State %nin% c("HI","AK","VI"))

## -- Use Mississippi River as a dividing point for WEst-East US --
MR_coords<-c(47.239722, -95.2075)
POS_Sampler<-as.numeric(US_META$Longitude <MR_coords[2])
# --- 1 are WEst US, 0 are East
US_META<-add_column(US_META,WE_US = POS_Sampler)

## --- Part b: Load samples data ---
DATA<-as_tibble(read.csv(file.path(path_data,"IMPROVE_2015_data_w_UNC_v2.csv")))

## --- Part c: Select samples from SW given site identifiers from SW_META table ("Code")
US_DATA_all<-as_tibble(DATA %>% filter(SiteCode %in% US_META$Code))
```

```{r,"Part D: Check for gross absorbance violations"}
# Let's identify any samples that (grossly) violate PM2.5 mass balances
# PM2.5 (=Y) cannot be negative!
# Since there's some probability that PM2.5 is negative due to errors at low concentration, we may use PM2.5 uncertainties to remove samples that fall outside -3*PM2.5_UNC.
# In this way, we don't risk censoring the data but do remove likely erroneous data.
US_DATA_all<-US_DATA_all %>% dplyr::filter(PM2.5 > -3*PM2.5_UNC)
```

```{r, "Screen proxies, constructs, PM, and useless things"}
exclude<-c("PM10","POC","ammNO3","ammSO4","SOIL","SeaSalt","OC1","OC2","OC3","OC4","EC1","EC2","EC3","fAbs_MDL","fAbs")
US_DATA_LRG<- US_DATA_all %>% dplyr::select(!contains(exclude) & !matches("_UNC") | matches("PM2.5_UNC"))
any(is.na(US_DATA_LRG))
US_DATA_LRG<-US_DATA_LRG[which(complete.cases(US_DATA_LRG)),]
any(is.na(US_DATA_LRG))
```

```{r, "Part F: Partition data into training and testing sets"}
## --- Instead of random partitioning, I will partition by first sorting samples by SiteCode and DATE (already done) and place every other sample in the test set.
# --- This data has seasonality. Sorting by date therefore ensures seasonality is equivalent between datasets
n<-nrow(US_DATA_LRG)
ind_test<-seq(1,n,2)
US_DATA_LRG_test<-US_DATA_LRG[ind_test,]
US_DATA_LRG<-US_DATA_LRG[-ind_test,]
```

### --- Step 2: Descriptive prior to GMM ---

```{r, "Part 1: The usual descriptives", warning=FALSE,message=FALSE,fig.cap="Figure (2.1) A2.2a: Aide-by-side Boxplots for fAbs and EC"}
# --- Plot of abs and EC ---
ggplot(US_DATA_LRG,aes(x=SiteCode,y=PM2.5,color=SiteCode))+
  geom_boxplot()+
  theme(plot.title=element_text(hjust = 0.5))+
  scale_y_log10(limits=c(0.001,100))+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size=4))
```

```{r, "Part 3: Correlation plot"}
R<-cor(US_DATA_LRG %>% dplyr::select(!all_of(c("SiteCode","Date","PM2.5_UNC"))))
corrplot(R,order="hclust")
```

### --- Step 2: Data prep for GMMs with mclust ---

```{r, Part 1: Normalization-- Decided to nullify in the 11th hour}
## --- Normalize US data by PM2.5 conc --
US_DATA_LRG_PM_norm<-US_DATA_LRG %>% dplyr::select(!c(PM2.5_UNC,SiteCode,Date,PM2.5)) %>% mutate(across(everything()),./ 1) 
## --- Save factor to merge back into DF ---
US_DATA_LRG_factors<-US_DATA_LRG %>% dplyr::select(c(SiteCode,Date,PM2.5_UNC))
  
## --- Do the same for the test set ---
US_DATA_LRG_PM_norm_test<-US_DATA_LRG_test %>%
dplyr::select(!c(SiteCode,Date,PM2.5_UNC,PM2.5)) %>% transmute(across(everything()),./ 1) 

## --- Save factor to merge back into DF ---
US_DATA_LRG_test_factors<-US_DATA_LRG_test %>% dplyr::select(c(SiteCode,Date,PM2.5_UNC))

## --- FInal output (I'm sure there's a cleaner way to do this) ---
US_DATA_LRG_PM_norm1<-bind_cols(US_DATA_LRG_factors,US_DATA_LRG_PM_norm)
US_DATA_LRG_PM_norm_test1<-bind_cols(US_DATA_LRG_test_factors,US_DATA_LRG_PM_norm_test)

## --- Remove bad division by PM2.5 ---
logic_complete<-complete.cases(US_DATA_LRG_PM_norm1)
logic_complete_test<-complete.cases(US_DATA_LRG_PM_norm_test1)
US_DATA_LRG_PM_norm<-US_DATA_LRG_PM_norm1[complete.cases(US_DATA_LRG_PM_norm1),]
US_DATA_LRG_PM_norm_test<-US_DATA_LRG_PM_norm_test1[complete.cases(US_DATA_LRG_PM_norm_test1),]

```

```{r, "Check data integrity"}
any(is.na(US_DATA_LRG_PM_norm))
any(is.na(US_DATA_LRG_PM_norm_test))
```

```{r, "Principal Component Analysis pretreatment",warning=FALSE}
## --- Need to preprocess with PCA as these data are too large (and EM alg. will probs. lead to non-convergance for high cluster #---
## ----
US_PCA_DATA_slim<-as_tibble(dplyr::select(US_DATA_LRG_PM_norm,!contains(c("SiteCode","Date","PM2.5","PM2.5_UNC"))))
US_PCA_DATA_slim_test<-as_tibble(dplyr::select(US_DATA_LRG_PM_norm_test,!contains(c("SiteCode","Date","PM2.5","PM2.5_UNC"))))
### --- log transform ---

##Go through each row and determine if a value is zero
#row_sub = apply(US_PCA_DATA_slim, 1, function(row) all(row > 0))
#log_US_PCA_DATA_slim<-log(US_PCA_DATA_slim[row_sub,])

##Subset as usual
#log_US_PCA_DATA_slim<-log_US_PCA_DATA_slim[row_sub,]

### --- PCA with PCAtools package ---
# Damn! It does a transposed form of PCA bleh ---
US_PCA<-pca(US_PCA_DATA_slim,transposed = TRUE)

## --- Find elbow point on screeplot ---
elbow <- findElbowPoint(US_PCA$variance)
elbow  
horn <- parallelPCA(US_PCA_DATA_slim)
horn$n
```
```{r}
## --- Screeplot ---
  PCAtools::screeplot(US_PCA,
    components = getComponents(US_PCA, 1:10),vline = c(horn$n, elbow))+ggtitle("Explained Variance plot")+theme(plot.title = element_text(hjust=0.5))+
    geom_label(aes(x = horn$n +0.5, y = 75,
      label = 'Horn\'s Method', vjust = 0, size = 5)) +
    geom_label(aes(x = elbow + 0.5, y = 55,
      label = 'Elbow method', vjust = 0, size = 5))

## --- Extract scores ---
scores<-as_tibble(US_PCA$rotated)
#names(scores)[31] <- "SiteCode"
## --- Extract scores and add to main data frame ---
US_DATA_w_scores<-add_column(US_DATA_LRG[logic_complete,],scores)
## --- Extract loadings (format as tibble)---
loadings<-as_tibble(US_PCA$loadings,rownames="species")
loadings
```

```{r}
## --- Project test samples onto principal components ---
## --- Reformat for use with predict.prcomp
  US_PCA.prcomp <- list(sdev = US_PCA$sdev,
    rotation = data.matrix(US_PCA$loadings),
    x = data.matrix(US_PCA$rotated),
    center = TRUE, scale = FALSE)

  class(US_PCA.prcomp) <- 'prcomp'
## -- Estimate test set scores ---
scores_test<-as_tibble(predict(US_PCA.prcomp, newdata = US_PCA_DATA_slim_test))
```

```{r, "PC Loading plots against species"}
## --- PC1 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC1,color=PC1))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Organic Carbon Component")+theme(plot.title = element_text(hjust = 0.5))

## --- PC2 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC2,color=PC2))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Total Anion component (NO3+SO4)")+theme(plot.title = element_text(hjust = 0.5))

## --- PC3 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC3,color=PC3))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Contrast between NO3 and SO4")+theme(plot.title = element_text(hjust = 0.5))

## --- PC4 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC4,color=PC4))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Soil (Al,Ca,Fe,Si)")+theme(plot.title = element_text(hjust = 0.5))

## --- PC5 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC5,color=PC5))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Mixed/Ambiguous")+theme(plot.title = element_text(hjust = 0.5))

## --- PC6 ---
ggplot(data = loadings, mapping=aes(x=species,y=PC6,color=PC6))+geom_point()+
  theme(legend.position = "none",axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ggtitle("Marine Aerosol (Na,Cl; -) with marginal EC contrast (+)")+theme(plot.title = element_text(hjust = 0.5))

```

```{r, "PC(1,2) Score plots colored based on high loadings"}
P2<-ggplot(data =US_DATA_w_scores,aes(x = PC1, y = PC2)) +
	geom_point(mapping = aes(color = log(SO4+NO3)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(1,2) scores: log Anions (NO3+SO4)")
P1<-ggplot(data =US_DATA_w_scores,aes(x = PC1, y = PC2)) +
	geom_point(mapping = aes(color = log(OC)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(1,2) scores: log Organic Carbon (OC)")

grid.arrange(P1,P2,nrow=1)
```

```{r, "PC(3,4) Score plots colored based on high loadings"}
P3<-ggplot(data =US_DATA_w_scores,aes(x = PC3, y = PC4)) +
	geom_point(mapping = aes(color = log(SO4)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(3,4) scores: log sulfate (SO4)")

P4<-ggplot(data =US_DATA_w_scores,aes(x = PC3, y = PC4)) +
	geom_point(mapping = aes(color = log(NO3)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(3,4) scores on log nitrate (NO3)")

# --- IMPROVE Soil equation ---
# --- Attests to the general validity of the soil equation ---
# SOIL Eqn = 2.20*Al + 2.49*Si + 1.63*Ca + 2.42*Fe + 1.94*Ti

P5<-ggplot(data =US_DATA_w_scores,aes(x = PC3, y = PC4)) +
	geom_point(mapping = aes(color = log(2.2*AL+2.49*SI+1.63*CA+2.42*FE+1.94*TI)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(3,4) scores: log Soil (Si)")

## --- Not the most efficient but whatevs ---
ind_grp <- US_DATA_w_scores %>% group_by(SiteCode) %>% group_indices
US_META_Slim<-US_META %>% filter(Code %in% US_DATA_w_scores$SiteCode)
EW<-rep(NA,length(US_DATA_w_scores$SiteCode))
for(k in 1:length(unique(US_DATA_w_scores$SiteCode))){
    EW[ind_grp==k]<-US_META_Slim$WE_US[k]
}
US_DATA_w_scores<-add_column(US_DATA_w_scores,EW_indicator=EW)
## --- East-West binary color coding ---
# --- Nopt informative
P6<-ggplot(data =US_DATA_w_scores,aes(x = PC3, y = PC4)) +
	geom_point(mapping = aes(color = EW))+
  theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+
  ggtitle("PC(3,4) scores: East-West divide")

grid.arrange(P3,P4,P5,nrow=1)

```

```{r, "PC(5,6) Score plots colored based on high loadings"}
# --- Total carbon: TC = OC + EC---
P6<-ggplot(data =US_DATA_w_scores,aes(x = PC5, y = PC6)) +
	geom_point(mapping = aes(color = log(OC+EC)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(5,6) scores: log Carbon (OC+EC)")
# --- Pyrolyzed OC (=OP) ---
P7<-ggplot(data =US_DATA_w_scores,aes(x = PC5, y = PC6)) +
	geom_point(mapping = aes(color = log(OP)))+theme(plot.title = element_text(hjust = 0.5,size=7),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(5,6) scores: log pyrolyzed OC (=OP)")
# --- IMPROVE Eqn for Marine Aerosol: 1.8*Cl

P8<-ggplot(data =US_DATA_w_scores,aes(x = PC5, y = PC6)) +
	geom_point(mapping = aes(color = log(1.8*CL)))+theme(plot.title = element_text(hjust = 0.5,size=8),legend.position = "none")+ scale_color_gradientn(colours = rainbow(20,start=0.25,end=1))+ggtitle("PC(5,6) scores: log Sea Salt")

grid.arrange(P7,P8,nrow=1)
```

### --- Step 3: Gaussian Mixture Models: clustering on components ---

```{r}
# --- Step 3.1: Number of PCs to consider ---
num_PCs<-6
num_clust<-10 #Interest of simplicity
# --- Step 2: Select scores from US_DATA_scores structure ---
GMM_scores<-US_DATA_w_scores %>% dplyr::select(num_range(prefix="PC",range=1:num_PCs))
```

```{r}
# --- Step 3.1: GMM mixture model initialization with k-means---
k_clust=100
kmeans_partition<-kmeans(GMM_scores, k_clust, iter.max = 100, nstart = 1)

# --- Step 3.2: Further Initialization with HCA ---
hc_out<-hc(GMM_scores,partition = kmeans_partition$cluster,minclus=1,hcUse="VARS")
#--- Don't quite see how to use this yet... This is a bit buggy

# --- Step 3.3: Option to specify noise... That's interesting
# --- We have uncertainties for PM2.5: therefore we can estimate noise as samples < minum detection limit where MDL ~= 3*min(UNC)
PM_noise<-which(US_DATA_LRG$PM2.5 <3*min(US_DATA_LRG$PM2.5_UNC))
# --- PErhaps we can make a good signal-to-noise ratio argument ---
SNR<-US_DATA_LRG %>% dplyr::select(PM2.5,PM2.5_UNC,SiteCode,Date)%>% mutate(SNR_PM = PM2.5/PM2.5_UNC,Date =as.Date(Date,"%m/%d/%Y")) 

SNR_sort<-arrange(SNR,Date)

qplot(x=as.factor(Date),y=SNR_PM,data=SNR_sort,geom="boxplot",
  main = "Signal-to-noise ratio: PM2.5",xlab="Date",ylab="SNR")+theme(plot.title=element_text(hjust = 0.5))+ geom_smooth(method= "loess",span=0.1 ,se=FALSE, aes(group=1))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

PM_noise<-which(SNR$SNR_PM <quantile(SNR$SNR_PM,0.05) | SNR$SNR_PM > quantile(SNR$SNR_PM,0.95))

```

```{r}
# --- Step 3.4: Run GMM with initial paramters ---
init_list<-list(hcPairs=NULL,noise=PM_noise)
# --- It'd be nice if I could use noise to 
#GMM_BIC<-mclustBIC(GMM_scores,G=1:num_clust,initialization = init_list)

load("GMM_BIC_10_clust_init_SNR.RData")
#save("GMM_BIC",file="GMM_BIC_10_clust_init_SNR.RData")
```

```{r, "Step 4: Diagnostic plots for GMM"}
plot(GMM_BIC)
```

```{r, SUmmary of best models}
summary(GMM_BIC)
```

```{r}
BIC_best <- Mclust(GMM_scores, x = GMM_BIC)
summary(BIC_best, parameters = TRUE)
```

```{r, Warning=FALSE}
plot(BIC_best, what = "classification")
```

```{r}
mod1dr<- MclustDR(BIC_best,lambda=1)
plot(mod1dr, what = "boundaries",ngrid=200)
```

```{r}
# --- Fit base-case weighted LS model ---

w_ii<-1/US_DATA_LRG$PM2.5_UNC^2
test_fit<-lm(PM2.5~OC+EC+OP+NO3+SO4,data=US_DATA_LRG,weights=w_ii)

plot(test_fit)

## --- Predict ---
PM2.5_test<-predict.lm(test_fit,US_DATA_LRG_test)

e_ii<-US_DATA_LRG_test$PM2.5-PM2.5_test
e_scaled<-e_ii/US_DATA_LRG_test$PM2.5_UNC

## --- Structure for further analysis ---
US_DATA_test_errors1<-US_DATA_LRG_test %>% dplyr::select(SiteCode,Date,PM2.5,PM2.5_UNC) %>% mutate(Date =as.Date(Date,"%m/%d/%y"), e_test=e_ii,e_scaled=e_ii/PM2.5_UNC)

## --- Classify test samplse with GMM ---
GMM_class_test<-predict.Mclust(BIC_best,scores_test[,1:num_PCs])

US_DATA_test_errors<-add_column(US_DATA_test_errors1,GMM_class=GMM_class_test$classification)
```

```{r}
## --- Errors by date ---
ggplot(data=US_DATA_test_errors,aes(x=Date,y=e_scaled))+ geom_boxplot(aes(group=Date))+
  theme(plot.title=element_text(hjust = 0.5))+geom_smooth(method= "loess",span=0.05 ,se=FALSE, aes(group=1))+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ylab(TeX("$\\frac{e_{i}}{\\sigma_{i}}$"))+ggtitle("Normalized errors by date")

## --- Errors by cluster ---
ggplot(data=US_DATA_test_errors %>% filter(GMM_class!=0),aes(x=as.factor(GMM_class),y=e_scaled))+ geom_boxplot(aes(group=GMM_class))+
  theme(plot.title=element_text(hjust = 0.5))+ylab(TeX("$\\frac{e_{i}}{\\sigma_{i}}$"))+ggtitle("Normalized errors by GMM cluster")+xlab("Cluster ID")

## --- Cluster statistics ---
#US_DATA_LRG_w_err<-add_column(e_scaled=e_scaled,US_DATA_LRG_PM_norm_test,.before="SiteCode")

US_DATA_test_w_stack<-stack(dplyr::select(US_DATA_LRG_PM_norm_test,!c("SiteCode","Date")))

US_DATA_test_stack_GMM<-add_column(US_DATA_test_w_stack,GMM_ID =rep(GMM_class_test$classification,length(levels(US_DATA_test_w_stack$ind))))

## --- Let's look only at the clusters that show high error ---
med_all_site<-apply(US_DATA_LRG_PM_norm_test[-c(1,2)],2,median)
med_sites<-tibble(species=names(med_all_site),medians=med_all_site)

ggplot(US_DATA_test_stack_GMM %>% dplyr::filter(GMM_ID == c(10)), aes(x = reorder(ind,values,FUN=median,na.rm=TRUE), y = values)) +
  geom_boxplot()+geom_line(data=med_sites,aes(x=species,y=medians,group=1))+
  theme(plot.title=element_text(hjust = 0.5),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1,size=4))+ylab("Concentration")+xlab("Species")
  #+ geom_smooth(data=US_DATA_test_stack_err_GMM,method= "loess",span=0.1 ,se=FALSE, aes(group=1))
```

```{r}
```


### --- Step 3: PCA and US maps with the spatial toolbox (on hold) ---

```{r}
# Things to try tomorrow: need to understand spatial objects from raster,sf, or sp class
# All else is just details

# --- Also attach state, Lat, and lon data to main data frame ---

# --- Maybe also consider CV recons

```




```{r, "Let's see what tmap package has to offer"}
data("World")

tm_shape(World) +
    tm_polygons("HPI")
```

```{r}
US_DATA_sf<- st_as_sf(US_DATA_LR, coords)


dsp <- SpatialPoints(META_DATA[,c("Longitude","Latitude")], proj4string=CRS("+proj=longlat +datum=NAD83"))
dsp <- SpatialPointsDataFrame(dsp, META_DATA)
US <- META_DATA$County #I think I need polygon info to make US map
# define groups for mapping
cuts <- c(0,200,300,500,1000,3000)
# set up a palette of interpolated colors
blues <- colorRampPalette(c('yellow', 'orange', 'blue', 'dark blue'))
pols <- list("sp.polygons", US, fill = "lightgray")
spplot(dsp, "Elevation", cuts=cuts, col.regions=blues(5), pch=20, cex=0.5)
```


